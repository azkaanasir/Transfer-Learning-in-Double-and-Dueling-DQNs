# RL- Final Project
Transfer Learning in Deep Q-Networks: A Comparative Study of DDQN and Dueling DQN Across Benchmark Environments

# ğŸ§  Transfer Learning in Deep Q-Networks

This repository contains the final report for our project titled:

**Transfer Learning in Deep Q-Networks: A Comparative Study of DDQN and Dueling DQN Across Benchmark Environments**

ğŸ“ *Authors: Azkaa Nasir, Fatima Dossa, Iqra Ahmed*  
ğŸ« *Dhanani School of Science and Engineering, Habib University*

## ğŸ“„ Project Summary

In this study, we explored how two deep reinforcement learning architectures â€” **Double DQN (DDQN)** and **Dueling DQN** â€” perform in both single-task and transfer learning settings. We trained both models on **CartPole-v1**, then attempted to transfer learning to **LunarLander-v2**.

Key focus areas included:
- Convergence speed
- Reward stability
- Generalization across environments

## ğŸ“ Contents

- `RL_Project_Report.pdf` â€“ Complete research paper with methodology, analysis, and findings

## ğŸ“Œ Highlights

- **Dueling DQN** learns faster and generalizes early, but is less stable.
- **DDQN** is more consistent and robust over longer training.
- Transfer learning between CartPole and LunarLander was **not effective**, due to complexity gaps and resource constraints.

---

Feel free to read the report for a detailed breakdown of results, challenges, and future research directions.

